---
title: "Running the BEACONs representation tools"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{representation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Intro
In this analysis we will use a set of benchmarks from BUILDER to assess land cover representation using the [2015 North American Land Cover map (NALC)](http://www.cec.org/north-american-environmental-atlas/land-cover-30m-2015-landsat-and-rapideye/). BUILDER creates reserves (hereafter ‘benchmarks’) by aggregating watershed catchments to a user defined size and intactness threshold. The output is a table listing the catchments making up each benchmark. The benchmarks we use here are created in the `builder` vignette in the `benchmarkbuilder` package.

Representation analyses typically include multiple layers assumed to represent a range of ecological processes. They often include climate layers, productivity, riparian zones etc. For simplicity, we will use a single layer (NALC) to assess representation of all 13 land cover classes that fall with our study area. The study are is a Fundamental Drainage Area in Yukon, Canada (FDA 09EA).

The goal of the representation analysis is to identify benchmarks that adequately capture the target amounts of representation classes (in our case NALC classes) deemed to be proportionally representative of the study region. Usually the target amounts should be met in full in a benchmark, rather than being split between multiple benchmarks. The idea being that the benchmark should provide a sufficient area for the ecological processes associated with specific target classes to operate. In a network of multiple benchmarks, different target classes and different ecological processes may therefore be represented by different benchmarks.

Note that the tools can accommodate different objectives. For example, meeting a set of targets across a network rather than meeting each target in full in a benchmark. We give an example of this below.

We use the following input datasets:

* `vignette_nalc`: The North American Land Cover dataset from 2015 with a resolution of 30m. Clipped to FDA 09EA.
* `vignette_catchments`: BEACONs catchments intersecting the study region.
* `vignette_benchmark_tab`: BUILDER output table for the study with benchmarks made to an area target of 500km2.
* `vignette_reserves`: Existing protected areas, extracted from the Canadian Protected and Conserved Areas Database and clipped to FDA 09EA.

There are two functions we can use to evaluate individual benchmarks: 

* `evaluate_targets_using_catchments()` pre-computes the class areas in the catchments. This method can only be used for benchmarks made in BUILDER because each benchmark is constructed of catchment planning units. Summing the pre-computed areas of the catchments making up a benchmark therefore gives the area of each class in the benchmark. This method is faster with large numbers of benchmarks because it minimizes geoprocessing of rasters.
* `evaluate_targets_using_clip()` clips the raster layer directly to each benchmark and calculates the area. This is slower but can be used on any polygon such as an existing protected area or a proposed protected area that was not built in BUILDER and therefore is not constructed of catchment planning units.

To demonstrate both of these functions, we will evaluate BUILDER benchmarks using `evaluate_targets_using_catchments()`, then we will evaluate the existing protected area network using `evaluate_targets_using_clip()` and add it to our analysis.

## View inputs
```{r, fig.width=7, fig.height=5, message=FALSE}
library(beaconstools)
library(dplyr)
library(sf)
library(raster)

fda <- vignette_catchments %>%
  summarise(geometry = st_union(geometry))

plot(vignette_nalc, axes = FALSE)
plot(vignette_catchments$geometry, add = TRUE)
```

## Preparing catchments
In order to use `evaluate_targets_using_catchments()` we first need to pre-compute the NALC areas in the catchments using `criteria_to_catchments()`.

```{r, message = FALSE}
# this can take ~5 minutes
catchments_nalc <- criteria_to_catchments(
  catchments_sf = vignette_catchments, 
  criteria_raster = vignette_nalc, 
  criteria_name = "nalc", 
  class_vals = unique(vignette_nalc))

print(catchments_nalc)
```

## Setting targets
We will use a target area of 500km2 for this analysis to match the approximate size of the benchmarks. The `gen_targets()` function calculates targets and lists them in the column `target_km2`, calculated as the proportion of each class across the raster, multiplied by the user provided `reserve_size`.


```{r}
# generate target table using study area boundary and LED map
target_table <- gen_targets(
  reference_sf = fda, 
  representation_raster = vignette_nalc, 
  reserve_size = 500)

print(as.data.frame(target_table))
```

## Evaluating individual benchmarks
The first step in the representation analysis is to evaluate each benchmark individually to see if any meet all class targets. We do this with `evaluate_targets_using_catchments()` which sums the class areas in each benchmark using the catchments and returns the class sums compared to the target values in a long table.
```{r}
benchmark_results <- evaluate_targets_using_catchments(
  catchments_sf = catchments_nalc, 
  criteria_name = "nalc", 
  benchmark_table = vignette_benchmark_tab, 
  target_table = target_table, 
  network_list = colnames(vignette_benchmark_tab))

# view the first benchmark
print(benchmark_results)
```
For reference we will also generate polygons for all 166 benchmarks so we can view their locations on the NALC map.
```{r, fig.width=7, fig.height=5}
benchmark_polygons <- dissolve_catchments_from_table(catchments_sf = vignette_catchments, 
                                             input_table = vignette_benchmark_tab, 
                                             out_feature_id = "network")

plot(vignette_nalc, axes = FALSE)
plot(benchmark_polygons$geometry, add = TRUE, border = 'yellow', lwd = 1.5)
```

## Evaluating existing protected areas
Some representation analyses will need to use non-benchmark reserves as input, either alone or in addition to benchmarks from BUILDER. We will evaluate representation for the existing reserves (clipped to our study region) using `evaluate_targets_using_clip()`. The output tables from `evaluate_targets_using_clip()` are the same format as from `evaluate_targets_using_catchments()`.

```{r, fig.width=7, fig.height=5}
# plot the 3 reserves inside study region
plot(vignette_nalc, axes = FALSE)
plot(vignette_reserves$geometry, add=TRUE, lwd = 1.5, border = 'yellow')

# evaluate the 3 reserves using targets
pa_results <- evaluate_targets_using_clip(
  reserves_sf = vignette_reserves, 
  reserves_id = "reserve", 
  representation_raster = vignette_nalc, 
  target_table = target_table)

print(pa_results)
```

## Summarizing individual reserves
At this point we have representation results for all individual benchmarks, as well as 3 existing reserves. We can use `summarize_representation_results()` to rank the reserves in terms of representation. We first append the reserve results to the benchmark results to get everything in one table. We then summarize the results, requiring 100% of the targets to be met, but only considering targets that cover >=1% of the total target area (rare targets are difficult to represent and are often addressed as a separate part of a conservation analysis).
```{r}
# add reserve evaluation results to benchmark_results
benchmark_results <- rbind(benchmark_results, pa_results)

# summarize
benchmarks_summary <- summarize_representation_results(
  network_evaluation_table = benchmark_results,
  criteria_name = "nalc", 
  target_pass_proportion = 1, 
  target_inclusion_proportion = 0.01, 
  suffix = "", 
  gaps = TRUE)

print(benchmarks_summary[order(benchmarks_summary$nalc_gaps),])

# Map the benchmarks with the least representation gaps (i.e. 3 gaps)
plot(vignette_nalc, axes = FALSE)
plot(benchmark_polygons$geometry[benchmarks_summary$nalc_gaps==3], add = TRUE, border = 'yellow', lwd = 1.5)
```

The best benchmarks have 3 representation gaps. There are 23 of these. The existing reserves all have 6 or more gaps. Since no benchmarks pass all of our required targets we will now combine multiple benchmarks into networks to try and meet all targets.

## Networks
There are multiple ways we could build networks for our study region depending on our conservation objectives. Below we demonstrate two networking options with different conservation goals.

### Two non-overlapping benchmarks, ignoring existing PAs
The first scenario involves planning a network of new ecological benchmarks that meet our representation targets. This is a common scenario in areas where there are no existing reserves, or where existing reserves do not meet conservation goals (i.e. too small, not representative of region).

The analysis steps for this scenario involve building a list of network names to evaluate, removing any overlapping networks from the list (because our scenario requires a network of multiple distinct benchmarks), combining the benchmark representation results into network results, and finally ranking the resulting networks. Once we have some networks to choose from we can build their polygons and view them on a map.

```{r, fig.width=7, fig.height=5}
# generate all possible network names using 2 benchmarks per network
network_names <- gen_network_names(
  in_names = colnames(vignette_benchmark_tab), 
  k = 2)

head(network_names)
length(network_names)

# now identify all networks where the two benchmarks are overlapping and remove these from the network 
# list
# this requires feeding the benchmarks sf object into list_overlapping_benchmarks()
overlaps <- list_overlapping_benchmarks(
  benchmarks_sf = benchmark_polygons)

length(overlaps)

# remove names of overlapping networks from network_names list
network_names <- network_names[!network_names %in% overlaps]

length(network_names)

# evaluate networks using evaluate_targets_using_benchmarks(). We could also use 
# evaluate_targets_using_catchments() but since we already have the individual benchmark results, 
# evaluate_targets_using_benchmarks() will be faster. It simply returns the highest representation
# value across all benchmarks in the network.
# Note that this function is quite slow for large numbers of networks.
network_results <- evaluate_targets_using_benchmarks(
  benchmark_results = benchmark_results, 
  network_list = network_names)

# summarize
networks_summary <- summarize_representation_results(
  network_evaluation_table = network_results,
  criteria_name = "nalc", 
  target_pass_proportion = 1, 
  target_inclusion_proportion = 0.01, 
  suffix = "", 
  gaps = TRUE)

head(networks_summary)

# we have 714 networks that meet all the targets (i.e. they have zero gaps)
print(nrow(networks_summary[networks_summary$nalc_gaps == 0,]))

# make a plot showing the full footprint of the best 714 networks, along with an example of one 
# of the networks. Here we use benchmarks_to_networks() which uses the benchmark sf object we
# already made to make the network polygons. We could technically do this using 
# catchments_to_benchmarks() with the network names, but benchmarks_to_networks() is much faster.
network_polygons <- benchmarks_to_networks(
  benchmarks_sf = benchmark_polygons, 
  network_list = networks_summary$network[networks_summary$nalc_gaps == 0])

plot(vignette_nalc, axes = FALSE)
plot(network_polygons$geometry, add = TRUE, col = "darkgrey", border = "darkgrey")
plot(network_polygons$geometry[1], add = TRUE, border = 'yellow', lwd = 1.5)
```

### Adding a non-overlapping benchmark to compliment existing PAs
In this scenario we will assume that the existing reserve ‘Tombstone_1’ is our starting point for a conservation network. We will add an ecological benchmark to create a network, and we will require that the ecological benchmark should not overlap ‘Tombstone_1’. The process will be similar to our previous scenario, except this time we only want the network names that include ‘Tombstone_1’. We can use the `force_in` argument in `gen_network_names()` for this. We will then remove the names of any networks where the benchmark and ‘Tombstone_1’ intersect. The resulting list of network names will be fed into the evaluation functions.

```{r, fig.width=7, fig.height=5}
# generate all network names containing 'Tombstone_1' using force_in
network_names <- gen_network_names(
  in_names = benchmarks_summary$network, 
  k = 2,
  force_in = "Tombstone_1")

head(network_names)

# append the 'Tombstone_1' polygon to the benchmark_polygon sf object
benchmark_polygons <- append_reserve(
  benchmarks_sf = benchmark_polygons, 
  add_reserve = vignette_reserves[vignette_reserves$reserve == 'Tombstone_1',],
  reserve_name = "Tombstone_1")

overlaps <- list_overlapping_benchmarks(
  benchmarks_sf = benchmark_polygons)

# remove names of overlapping networks from network_names list
network_names <- network_names[!network_names %in% overlaps]

length(network_names)

# evaluate networks using evaluate_targets_using_benchmarks(). Note that benchmark_results already 
# contains the Tombstone_1 evaluation results that we added using rbind() earlier.
network_results <- evaluate_targets_using_benchmarks(
  benchmark_results = benchmark_results, 
  network_list = network_names)

# summarize
networks_summary <- summarize_representation_results(
  network_evaluation_table = network_results,
  criteria_name = "nalc", 
  target_pass_proportion = 1, 
  target_inclusion_proportion = 0.01, 
  suffix = "", 
  gaps = TRUE)

head(networks_summary[order(networks_summary$nalc_gaps),])

# No networks meet all the target.
# We have 27 networks that meet all but 2 of the targets
print(nrow(networks_summary[networks_summary$nalc_gaps == 2,]))

# make a plot showing the full footprint of the best 27 networks, along with an example of one of 
# the networks
network_polygons <- benchmarks_to_networks(
  benchmarks_sf = benchmark_polygons, 
  network_list = networks_summary$network[networks_summary$nalc_gaps == 2])

plot(vignette_nalc, axes = FALSE)
plot(network_polygons$geometry, add = TRUE, col = "darkgrey", border = "darkgrey")
plot(network_polygons$geometry[1], add = TRUE, border = "yellow", lwd = 1.5)
```

### Assessing targets across full network
Sometimes we might want to assess a set of targets across a full network, instead of requiring targets to be met in full in a benchmark. We can use either `evaluate_targets_using_catchments()` or `evaluate_targets_using_clip()` for this. Instead of providing a list of benchmark names, we can provide network names and the functions will sum target areas across the full extent of the network.
```{r, , fig.width=7, fig.height=5}
# Make polygons for 5 randomly selected networks as an example
network_polygons <- benchmarks_to_networks(
  benchmarks_sf = benchmark_polygons, 
  network_list = sample(network_names, 5))

network_results <- evaluate_targets_using_clip(
  reserves_sf = network_polygons, 
  reserves_id = "network", 
  representation_raster = vignette_nalc, 
  target_table = target_table)

summarize_representation_results(
  network_evaluation_table = network_results,
  criteria_name = "nalc", 
  target_pass_proportion = 1, 
  target_inclusion_proportion = 0.01, 
  suffix = "", 
  gaps = TRUE)
```